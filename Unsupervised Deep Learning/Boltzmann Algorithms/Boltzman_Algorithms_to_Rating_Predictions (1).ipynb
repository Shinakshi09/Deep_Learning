{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Boltzman Algorithms  to Rating Predictions ",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEc50M2wbbXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Importing  Libraries \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATabC-4CegL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" \n",
        "\n",
        "NOTE : This is the original dataset\n",
        "\n",
        "1. Header = None , which means There is no column name in the file\n",
        "2. Engine = Python , This is to make sure Dataset gets imported correctly\n",
        "3. Encoding = latin-1     , There are some special chracter in the movies title.\n",
        "\"\"\"\n",
        "\n",
        "movies = pd.read_csv(\"/content/drive/My Drive/Boltzmann Machine/ml-1m/movies.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv(\"/content/drive/My Drive/Boltzmann Machine/ml-1m/users.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv(\"/content/drive/My Drive/Boltzmann Machine/ml-1m/ratings.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42TGp9V9f7Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlgENCqWgbcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Here first column is the User_id\n",
        "Second column is the Gender\n",
        "Third column is the Age\n",
        "and fourth column is , It seems some codes to the users job\n",
        "\"\"\"\n",
        "\n",
        "users.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXE5gf9ihgYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "First column is id\n",
        "Second column is movies_id\n",
        "third column is  Ratings (1 to 5)\n",
        "fourth columns is Timestamp (Not really requirred)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1I7Q7JZJVhf",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62YY5wYehidx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" \n",
        "Preparing Training and Test Set \n",
        "NOte : Separater for this file is Tab hence using \\t parameter\n",
        "I am converting these dataset into numpy array because I am using PyTorch Tensors\n",
        "\"\"\"\n",
        "\n",
        "training_set = pd.read_csv(\"/content/drive/My Drive/Boltzmann Machine/ml-100k/u1.base\", delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv(\"/content/drive/My Drive/U/Boltzmann Machine/ml-100k/u1.test\", delimiter = '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxkGhDsslamM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "Getting the total number of users and Movies, Why Am I doing this?\n",
        "\n",
        "Because I will be converting my training_Set and test_Set into a matrix where lines are going to user and columns are \n",
        "going to be movies and cells are going to be the ratings.\n",
        "\n",
        "I will create such matrix for training set and test set both\n",
        "\n",
        "I will also include older users, older movies from original dataset into these two Matrixes \n",
        "\n",
        "And The Training set that we just imported, If a user did not rate the movies, We will put it a zero\n",
        "into the cell of matrix that corresponds to  this user and that movie\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-GLVi2ap4RK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "Going to convert our dataset into an array with users in lines and movies in columns\n",
        "\n",
        "Why Am i doing this?\n",
        "\n",
        "We will need to make a specific structure that will corresponds to  what the Restricted Boltzmann machine wants as input\n",
        "\n",
        "These observations will go one by one into the RBM. Hence will create a structure that will contain these observations\n",
        "that will go into the Network and their different features that are going to be into input nodes and that is what\n",
        "i will do by creating this array with users in lines and movies in the columns because we will have observations in lines and \n",
        "features in the columns. \n",
        "\n",
        "In other words, It is the same like we do in all neural networks or ML ALgorithms.\n",
        "\n",
        "I will accomplish this objective by creating a user defined function. I will give only one argument to this function\n",
        "because it will apply to only one set of data which will training set first and when we will apply this to our training set \n",
        "\n",
        "or test set, We only need to replace this argument by training set and test set, Then colon :\n",
        "\n",
        "after than I will tell the function what it needs to do\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1, nb_users + 1):\n",
        "    id_movies = data[:, 1] [data[:, 0] == id_users]\n",
        "    id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies - 1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdGjiBsiFQMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Converting the data into torch tensor \"\"\"\n",
        "\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnUaVK8hGLBp",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the Input for Boltzmann Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmk5gmnuGJ8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Converting Ratings into Binary 1 liked and 0 not liked\n",
        "Why am I doing this?\n",
        "Because I will need to predict some Binary ratings \n",
        "But question is why do we also need input to have Binary input format?\n",
        "Because RGM takes input vector and inside the input vector, It will predict the rating that was not originally rated by the user\n",
        "But since these originally ratings are rated already by the user, Then the predicted rating output must have the same format.\n",
        "\n",
        "Now I have used -1 here too, Let's understand why is that so?\n",
        "\n",
        "Because Will replace all the zeroes in the original training set, ALl the ratings that were not actually existent These corresponds to the movies that\n",
        "were not rated by the user but now since rating are gonna be zero and one, then Original zeroes must now have another value and this new value is gonna be \n",
        "\n",
        "minus one. So Minus one means that Movies were not rated\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79_S2jN8JIbu",
        "colab_type": "text"
      },
      "source": [
        "# Creating Architecture of RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZvIWat2Fa3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Now I will build a RBM model, RBM is probabilistic Graphical Model, I will be using Class to build this model.\n",
        "\n",
        "A CLass is model(Plan) of something we want to build, Let's say you want to build a house, YOU need model home, instructions and thats what a class will contain\n",
        " and the person who will make class will be the architect because He will define how a house should be built and once a class is made you can create\n",
        "\n",
        " some objects of this class. And object is nothing else but houses and that is exactly same for RBG model. I will be the architect for this model. I will make \n",
        "\n",
        " class that will define how the RBM should be built Hence In this class. I will give all the information that I need to build the RBM, SO What are these\n",
        "\n",
        " information\n",
        "\n",
        " 1. Number of hidden nodes\n",
        " 2. weights for probability of the visible node given the hidden node\n",
        " 3. bias for the same probability and bias for the probability of the visible node given the hidden node\n",
        " \n",
        " These are first parameters we need to initiaze the RBM. Hence Will put all this for first function called __init__ and then within the class we can add more things\n",
        "\n",
        " besides the parameters that defines the model. We can also add some functions.\n",
        "\n",
        " Just as an Architect can add more tools in making the model of the house. LIkewise I will write some function besides the __init__ function that will do all the \n",
        " And these actions are to sample the Hidden nodes and visible nodes. \n",
        "\n",
        " In Short, I will need around 3 functions\n",
        "\n",
        "1. Function to initialize the RBM\n",
        "2. Sample H that will sample the probabilities of the hidden nodes given the visible nodes\n",
        "3. Function to sample v that will sample the probabilities of the visible nodes given the hidden nodes\n",
        "\n",
        "\n",
        "SO one class and three functions to make \n",
        "\n",
        "Let's define the class using word 'class' and then class name, Make sure its name is in capital letter or at least starts with capital letter,\n",
        "then parrenthesis and colon.\n",
        "And As I have alredy talked above that first function we need to make is __init__ function hence will do that, This __init__ function has to be defined in\n",
        "every class because This init function will have parameters of the object that will be  created once the class is made.\n",
        "Here I Will have 3 arguments in __init__ function. First one will always be default parameters/argument that is self.\n",
        "\n",
        "This self corresponds to the object that will be created afterwards and we need this argument because I will define some variables and we need to specify\n",
        "These variables are the variables of the Object that will be created afterwards and not some global variables. \n",
        "\n",
        "And will put two another arguments. 1. NV - WHICH IS NUMBER OF VISIBLE Nodes and third is NH which is number of hidden nodes so these are just parameters of the __init__ function. \n",
        "\n",
        "And then I Will define what we need to initilize which is weights and bias hence now to define how this initialisation is going to work, I will need to add the column there :\n",
        "there.\n",
        "\n",
        "NOw within this __init__ function. We will initialize the parameters of our future objects that will create in this class. It will be all the parameters which\n",
        "will be optimized during the training of the RBM.\n",
        "\"\"\" \n",
        "\n",
        "\n",
        "\n",
        "class RBM():\n",
        "  def __init__(self, nv, nh):\n",
        "    self.W = torch.randn(nh, nv)\n",
        "    self.a = torch.randn(1, nh)\n",
        "    self.b = torch.randn(1, nv)\n",
        "  def sample_h(self, x):\n",
        "    wx = torch.mm(x, self.W.t())\n",
        "    activation = wx + self.a.expand_as(wx)\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "  def sample_v(self, y):\n",
        "    wy = torch.mm(y, self.W)\n",
        "    activation = wy + self.b.expand_as(wy)\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "\n",
        "  \"\"\"\n",
        "This last function is about constractive divergence  which is used to approximate the likelihood gradients, As we know that direct computation of the \n",
        "\n",
        "Gradient is too heavy therefore instead of computing it directly, I will try to approximate it. It comes with Gib Sampling consist of creating the Gibs chain\n",
        "\n",
        "And this Gibs chain is created by sampling k times the hidden nodes and divisible nodes. And To make this, We will add four arguments\n",
        "\n",
        "1. Input vector\n",
        "\n",
        "2. vk (visible nodes optained after k sampling)\n",
        "\n",
        "3. Ph0 that is vector of probabilities that is at the first\n",
        "\n",
        "4. phk corresponds to  probabilities of the hidden nodes after k sampling\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def train(self, v0, vk, ph0, phk):\n",
        "    self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "    self.b += torch.sum((v0 - vk), 0)\n",
        "    self.a += torch.sum((ph0 - phk), 0)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Now I will create the Object SO what do we do in Object is ...We just call the parameters nv and nh\n",
        "\"\"\"\n",
        "\n",
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "rbm = RBM(nv, nh)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xzGZlFiVl4-",
        "colab_type": "text"
      },
      "source": [
        "# Training the RBM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGfXBAf5VLu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Will create a loop which will go through each epochs batch passed through the network\n",
        " and at the end , Will get the final visible nodes will new ratings\n",
        " Will write the statement, Remember : Every Deep Learning algorithm need a loss function to measure the error, Then There is another for loop after Every batch\n",
        " of users going through the network. Rest everything is simple to understand hence not going to write everything here\n",
        "\n",
        "\"\"\"\n",
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "  train_loss = 0\n",
        "  s = 0.\n",
        "  for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "    vk = training_set[id_user : id_user + batch_size]\n",
        "    v0 = training_set[id_user : id_user + batch_size]\n",
        "    ph0,_ = rbm.sample_h(v0)\n",
        "    for k in range(10):\n",
        "      _,hk = rbm.sample_h(vk)\n",
        "      _,vk = rbm.sample_v(hk)\n",
        "      vk[v0<0] = v0[v0<0]\n",
        "    phk,_ = rbm.sample_h(vk)\n",
        "    rbm.train(v0, vk, ph0, phk)\n",
        "    train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
        "    s += 1.\n",
        "  print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98_WNf72jJnH",
        "colab_type": "text"
      },
      "source": [
        "# Testing the RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB-SU3o8XmWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user+1]\n",
        "    vt = test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) > 0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afpzmEtamEbu",
        "colab_type": "text"
      },
      "source": [
        "# Training RMSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x-9qTYClCku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "        vk = training_set[id_user:id_user+batch_size]\n",
        "        v0 = training_set[id_user:id_user+batch_size]\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        train_loss += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2)) # RMSE here\n",
        "        s += 1.\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MPx6Y_bmIbG",
        "colab_type": "text"
      },
      "source": [
        "# Test RMSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swt2uIgkl5IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user+1]\n",
        "    vt = test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) > 0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2)) # RMSE here\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUr6vmPcmPkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
